<!DOCTYPE html>
<html>
  <head>
    <title>Stat 585 - Testing Your Code</title>
    <meta charset="utf-8">
    <meta name="author" content="Susan Vanderplas" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="tweaks.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Stat 585 - Testing Your Code
### Susan Vanderplas

---

class: center, middle



## Outline
.left[
- Motivation

- Automated Testing and Unit Tests

- Testing in R: `testthat`

- Automatic Testing with TravisCI

- Test coverage with `covr`
]

---

## So you have a package

Workflow:

1. Write a function.

2. Load it with `Ctrl/Cmd + Shift + L` or `devtools::load_all()`

3. Experiment with it in the console to see if it works.

4. Rinse and repeat.

&lt;br/&gt;&lt;br/&gt;
--

Testing in this workflow is informal, but can be repetitive and tedious. 

---
class:middle,center
# Automated Testing

---

## Unit tests

Tests that evaluate one feature of a function



They are run automatically after you make changes to the code



Unit tests are one part of the larger framework of _Test Driven Development_


--

## Test Driven Development

_Test Driven Development_ is an approach to programming where the unit tests are written before the actual code

- Requirements are decided in advance

- Code must meet the requirements (and only the requirements)

---

## Why use unit tests?

For a bit of extra work, you get: 

- Fewer bugs
    - Essential functions are tested and issues are caught quickly
    - Visual confirmation that essential features are working
    - When debugging, write a test to pinpoint the bug (and stop it from reoccurring)

- Better code structure
    - Modular code: do only one thing per function
    - Document functions as you write them to satisfy tests

- Robust code 
    - make big changes quickly and without downstream problems
    - Any changes that break things should be caught with tests

- (in theory) Easier to start after a break:    
pick up at the last failed test and write code to satisfy that test

---

# Testing in R: `testthat`

---

## Tools for package testing

1. `testthat`: unit testing for R packages
  
  - structured R package testing
  
  - provides functions to set up and tear down testing environments
  
  - runs each set of tests in a clean environment
  
  - reports whether each test passes or fails

2. `usethis`: helper functions for R package development

  - set up `testthat` for your package: `use_testthat()`
  
  - create new test files: `use_test("testname")` creates a new test file

.small[Note: `testthat` works with packages. [This github issue](https://github.com/r-lib/testthat/issues/659) has a good discussion of testing outside of the package framework]

---

## Unit Testing Workflow

1. Modify your code or tests

2. Test your package (`Ctrl/CMD - Shift - T`)

3. Repeat until all tests pass

---
class:inverse
## Your Turn


```r
## install.packages(c("testthat", "usethis"))
library(testthat)
```

1. Install the `testthat` package for unit testing and the `usethis` package (helper functions to make package development easy)

2. Set up a github repository for your new package

3. Create a new R package, `helloR`, and set it up to work with `testthat`

```r
# Run create_package to add package infrastructure 
# Adjust the path to refer to your current project directory
usethis::create_package("../helloR") 
usethis::use_testthat()
```

What does your file structure look like now? 

---

## Testing Structure

A test file consists of 

1. context - a description of the test blocks in the file

2. one or more test blocks:    
`test_that(description, {test statements})`


```r
context("test-basics")

# Test block
test_that(
  # description
  "multiplication works",
  { # test statements inside this block
    expect_equal(2 * 2, 4)
  }
)
```
---

## Test Statements

`testthat` has a series of expectation functions:

function | description
---- | ----
`expect_equal(obj, value)` | Is the object equal to a value?
`expect_error(expr)` | Does the expression produce an error?
`expect_gt(obj, value)` | Is the object greater than the value?
`expect_length(obj, value)` | Does the object have length value?

See more with `help(package = "testthat")`

These functions are silent if the expectation is met, and throw an error otherwise.

Expectations are used to construct tests. 
&lt;!-- When included in a test file, they will be run automatically; when run on their own, you can see how they work --&gt;

---
class:inverse
## Your Turn - Writing Expectations

1. Create a test file with `usethis::use_test("mtcars")`

2. Write a set of expectations that test the `mtcars` data to make sure it has the correct format    
What are the important/essential features of the data?


.center[![:scale 30%](https://www.aliensthetruth.com/images/ufo-abduction.jpg)]
.center[If `mtcars` was abducted, would you notice?]

---

## Solutions

```r
data(mtcars)

# correct type
expect_s3_class(mtcars, "data.frame")

# correct dimensions
expect_equivalent(dim(mtcars), c(32, 11))

# correct column names
expect_named(mtcars, c("mpg", "cyl", "disp", "hp", "drat", 
                       "wt", "qsec", "vs", "am", "gear", "carb"))
```

---

## Solutions

```r
# hardcore option: use dput() to record mtcars structure
# dput(head(mtcars))
mtcars_head &lt;- structure(
  list(
    mpg = c(21, 21, 22.8, 21.4, 18.7, 18.1), 
    cyl = c(6, 6, 4, 6, 8, 6), 
    disp = c(160, 160, 108, 258, 360, 225), 
    hp = c(110, 110, 93, 110, 175, 105), 
    drat = c(3.9, 3.9, 3.85, 3.08, 3.15, 2.76), 
    wt = c(2.62, 2.875, 2.32, 3.215, 3.44, 3.46), 
    qsec = c(16.46, 17.02, 18.61, 19.44, 17.02, 20.22), 
    vs = c(0, 0, 1, 1, 0, 1), 
    am = c(1, 1, 1, 0, 0, 0), 
    gear = c(4, 4, 4, 3, 3, 3), 
    carb = c(4, 4, 1, 1, 2, 1)), 
  row.names = c("Mazda RX4", "Mazda RX4 Wag", "Datsun 710", 
                "Hornet 4 Drive", "Hornet Sportabout", "Valiant"), 
  class = "data.frame")
expect_equivalent(head(mtcars), mtcars_head)
```

Choose your tests carefully - too specific, and they'll break unnecessarily

---

## Test-Driven Development Workflow

1. Write out the specifications for your function

2. Create your test file `usethis::use_test("foo")`

3. Write tests for your function in `tests/testthat/test_foo.R`

4. Write your function and documentation in `R/foo.R`

5. Test your package: `Ctrl/CMD - Shift - T` or use the Build Menu

.center[![:scale 60%](rstudio-build-interface-tests.png)]

---

## Test-Driven Development Example

Function: `mymean(x, na.rm)`

Important behaviors: 

--

- issue an error when x is not numeric

--

- return a value equal to `sum(x)/length(x)` when x has no `NA` values or `na.rm = T`

- return `NA` when x has `NA`s and `na.rm = F`

---

## Test-Driven Development Example

Important behaviors: 

- issue an error when x is not numeric    
(or if x cannot be coerced to a numeric vector)

```r
x &lt;- letters[1:3]
expect_warning(mymean(x)) # This is the minimal test
expect_warning(mymean(x), # This tests for a specific warning
               "argument is not numeric or logical: returning NA") 
```

---

## Test-Driven Development Example

Important behaviors: 
- return a single numeric value equal to sum(x)/length(x)


```r
x &lt;- 1:8
y &lt;- c(1:8, NA)

# Test that mean(1:8) returns a numerically correct response
expect_equal(mymean(x), 4.5)

# Test that mean(c(1:8, NA)) equals mean(1:8) when na.rm = T
expect_equal(mymean(y, na.rm = T), mymean(x))
```

---

## Test-Driven Development Example

- return NA when na.rm = F and x has NAs

```r
# Can also test to see if a test fails...
expect_failure(
  expect_equal(mymean(c(1:8, NA), na.rm = F), mymean(c(1:8)))
)

# Or test if something returns NA
expect_true(is.na(mymean(c(1:8, NA))))
```

---
class:inverse
## Your Turn

In your `helloR` package, do the following: 

1. Create the file `R/mymean.R` for your `mymean` function

2. Create a test file for `mymean`: `usethis::use_test("mymean")`

3. Add the expectations in the previous slides to your test file

4. Write the `mymean` function in `R/mymean.R`

5. Save your test and code files, then test your package. Did your function pass?

---
class:inverse
## Your Turn

Create a new function for your `helloR` package. 

- Function specifications: 
    - name: `sign_root`
    - Parameters n and value, both numeric
        - Function should error if `n` or `value` is not numeric
    - Function should return a number 
        - with the same sign as `value`
        - with magnitude equal to the `n`th root of `value`.

1. Create a test file for this function and write appropriate tests

2. Write the function    
.small[Don't forget to add assertions to your function to check inputs!&lt;br/&gt;The `checkmate` package is your friend!]

3. Does your function pass your tests? How do your tests compare to your neighbor's?

---

## Solution - Tests


```r
context("sign_root")

# - Function specifications:
#   - name: `sign_root`
# - Parameters n and value, both numeric
# - Function should error if `n` or `value` is not numeric
# - Function should return a number
# - with the same sign as `value`
# - with magnitude equal to the `n`th root of `value`.

test_that("sign_root works as expected", {
  expect_error(sign_root(n = "a", value = 2))
  expect_error(sign_root(n = 2, value = "a"))
  expect_equivalent(sign_root(2, 4), 2)
  expect_equivalent(sign_root(2, -4), -2)
  expect_equivalent(sign_root(3, 8), 2)
  expect_equivalent(sign_root(3, -8), -2)
})
```

---

## Solution - Function


```r
#' Take the nth root of a value, but keep the sign intact
#'
#' @param n root to take (n = 2 would correspond to the square root)
#' @param value value to take the root of
#' @return the nth root of abs(value) with the sign of value
#' @export
sign_root &lt;- function(n = 2, value = 4) {
  checkmate::check_number(n, na.ok = T)
  checkmate::check_number(value, na.ok = T)

  abs(value) ^ (1/n) * sign(value)
}
```

---

## Unit tests are...

- Modular (by design)

- Quick to run

- Run in an clean environment&lt;br/&gt;    
    - Set up and Tear down tasks set up the environment for testing
    
- Independent - don't require outside files (traditionally)

---

## Unit tests

&gt; But, we're statisticians. What about the data?

- use tiny test data (`dput()` is helpful)

- read in toy data from files in the test directory

- use data included with the package

- use data included in base R

- download data from elsewhere with a set-up function, delete it with a tear-down function
    - tests will fail without internet or if the site is down

---
class:middle,center
# Continuous Integration - TravisCI

---

## Motivation

The package build - modify - test cycle can be tedious. 

Sometimes, your package is written in a way that depends on your R environment. 

How do you determine if things will work on a different computer?

--

You test the package build/install process as well!

---

## Continuous Integration

[Travis CI](https://travis-ci.org/) can be used with github to automatically 
1. set up a test environment
2. install all dependencies
3. build your package
4. run all tests
5. (optional) calculate code coverage and upload to a service like [codecov.io](https://codecove.io)

---

## Continuous Integration

Setting up Travis for your R package:

1. [Make an account](https://travis-ci.org/) and link to your GitHub account
2. Switch Travis monitoring on [for the repository of your choice](https://travis-ci.org/account/repositories)
![:scale 60%](switch_travis_repo_on.png)

---

## Continuous Integration

Setting up Travis for your R package:

1. [Make an account](https://travis-ci.org/) and link to your GitHub account
2. Switch Travis monitoring on [for the repository of your choice](https://travis-ci.org/account/repositories)
3. Enable travis for your package: `usethis::use_travis()`

A new build will be triggered when you push changes to your github repository.

---
class:inverse
## Your Turn

1. Set up travis for your helloR repository

2. Try to get your travis build working. You may have to: 
    - add documentation    
    (Build menu -&gt; Generate documentation with roxygen, then Ctrl/Cmd-Shift-D)
    
    - add a license: `usethis::use_gpl3_license(name="your name")`
    
    - Run `devtools::check()` (Ctrl/CMD-Shift-E)
    
    - Make sure your tests pass

---

## Continuous Integration

&lt;blockquote class="twitter-tweet" data-lang="en"&gt;&lt;p lang="en" dir="ltr"&gt;Things are going great; why do you ask?! &lt;a href="https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#rstats&lt;/a&gt; 

![:scale 70%](https://pbs.twimg.com/media/CgbixfuVAAAWgZn.jpg)

&lt;/p&gt;&amp;mdash; Julia Silge (@juliasilge) &lt;a href="https://twitter.com/juliasilge/status/722514130968535042?ref_src=twsrc%5Etfw"&gt;April 19, 2016&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;

---

## Continuous Integration

The last Your Turn resulted in...
![](travis_is_depressing.png)

.center[![:scale 70%](travis_is_depressing2.png)]

---

# Code Coverage: `covr`

---

## Code Coverage

&gt; How many unit tests are enough? Is everything tested?

- `covr` is a package that will:
    1. build your package in a clean environment 
    2. run your tests
    3. determine how many times each line was evaluated (through [magic](https://cran.r-project.org/web/packages/covr/vignettes/how_it_works.html))
    4. launch a Shiny app to show you line-by-line coverage reports
    
- 100% coverage is good, but unit tests aren't everything
    - Some lines aren't worth testing
    - Integration testing matters too!


```r
covr::report() # Run a local code coverage report

# Enable codecov.io with your github account
# This requires travis integration, but generates coverage reports 
#   automatically with every change you push to the github repo
usethis::use_coverage(type = "codecov") 
```

---
class:inverse
## Your Turn

1. Run a code coverage report locally for your helloR package using `covr::report()`

2. Stretch goal: Try to get coverage configured using [codecov.io](https://codecov.io/github/srvanderplas/helloR?branch=master)
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="macros.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script>
(function() {
  var i, text, code, codes = document.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
})();
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
